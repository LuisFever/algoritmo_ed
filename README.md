# üß¨ Algoritmo de Evoluci√≥n Diferencial en Python

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/status-active-success.svg)]()

> Implementaci√≥n educativa completa del Algoritmo de Evoluci√≥n Diferencial (Differential Evolution) con ejemplos pr√°cticos y documentaci√≥n detallada en espa√±ol.

## üìã Tabla de Contenidos

- [Acerca del Proyecto](#-acerca-del-proyecto)
- [Caracter√≠sticas](#-caracter√≠sticas)
- [Instalaci√≥n](#-instalaci√≥n)
- [Uso R√°pido](#-uso-r√°pido)
- [Archivos del Proyecto](#-archivos-del-proyecto)
- [Ejemplos](#-ejemplos)
- [Teor√≠a](#-teor√≠a)
- [Contribuir](#-contribuir)
- [Licencia](#-licencia)

## üéØ Acerca del Proyecto

Este proyecto contiene una implementaci√≥n educativa del **Algoritmo de Evoluci√≥n Diferencial**, un m√©todo de optimizaci√≥n metaheur√≠stica especialmente efectivo para problemas de optimizaci√≥n continua.

### ¬øQu√© es Evoluci√≥n Diferencial?

Es un algoritmo de b√∫squeda que encuentra valores √≥ptimos de variables que minimizan (o maximizan) una funci√≥n objetivo. Funciona simulando una evoluci√≥n de poblaci√≥n donde los individuos mejoran usando las **diferencias** entre otros individuos.

**Creado por:** Rainer Storn y Kenneth Price (1997)

## ‚ú® Caracter√≠sticas

- üìö **C√≥digo educativo** - M√°s de 1000 l√≠neas de comentarios explicativos
- üéì **3 niveles de complejidad** - Desde ultra simple hasta aplicaciones reales
- üìä **Visualizaciones incluidas** - Gr√°ficas autom√°ticas de convergencia
- üîß **F√°cil de personalizar** - Adapta el c√≥digo a tu problema
- üåê **Documentaci√≥n completa** - En espa√±ol, con ejemplos paso a paso
- ‚úÖ **Sin errores** - C√≥digo probado y funcional

## üöÄ Instalaci√≥n

### Requisitos
- Python 3.7 o superior
- pip (gestor de paquetes de Python)

### Pasos

1. Clona el repositorio:
```bash
git clone https://github.com/TU-USUARIO/algoritmo-evolucion-diferencial.git
cd algoritmo-evolucion-diferencial
```

2. Instala las dependencias:
```bash
pip install -r requirements.txt
```

¬°Listo! Ya puedes usar el c√≥digo.

## üí° Uso R√°pido

### Opci√≥n 1: Ejemplo Ultra Simple (Recomendado para empezar)

```bash
python ejemplo_ultra_simple.py
```

Este ejemplo:
- ‚úÖ Muestra paso a paso qu√© hace el algoritmo
- ‚úÖ Explica cada operaci√≥n (mutaci√≥n, cruce, selecci√≥n)
- ‚úÖ Perfecto para aprender c√≥mo funciona

### Opci√≥n 2: Ejemplos Completos

```bash
python diferencial_evolution_ejemplo.py
```

Incluye:
- 3 funciones de prueba (Esfera, Rastrigin, Rosenbrock)
- Gr√°ficas de convergencia
- Comparaci√≥n de par√°metros

### Opci√≥n 3: Aplicaci√≥n Pr√°ctica

```bash
python aplicacion_practica.py
```

Resuelve un problema real: ajuste de curvas de enfriamiento.

## üìÅ Archivos del Proyecto

| Archivo | Descripci√≥n | L√≠neas |
|---------|-------------|--------|
| `ejemplo_ultra_simple.py` | Versi√≥n minimalista con visualizaci√≥n detallada | ~200 |
| `diferencial_evolution_ejemplo.py` | Implementaci√≥n completa con clase reutilizable | ~480 |
| `aplicacion_practica.py` | Aplicaci√≥n real: ajuste de curvas | ~350 |
| `README_EvolucionDiferencial.md` | Teor√≠a completa del algoritmo | - |
| `EJEMPLO_PASO_A_PASO.txt` | Ejemplo manual con n√∫meros concretos | - |
| `GUIA_PARA_EXPLICAR.txt` | Gu√≠a r√°pida para presentaciones | - |
| `GUIA_VISUAL_ALGORITMO.txt` | Diagramas y flujos en ASCII art | - |
| `EXPLICACION_SIMPLE.md` | Analog√≠as y explicaciones simples | - |
| `INSTRUCCIONES.txt` | Gu√≠a de instalaci√≥n y uso | - |

## üìñ Ejemplos

### Ejemplo 1: Minimizar una funci√≥n simple

```python
from diferencial_evolution_ejemplo import EvolucionDiferencial

# Define tu funci√≥n objetivo
def mi_funcion(x):
    return x[0]**2 + x[1]**2  # Minimizar x¬≤ + y¬≤

# Configura los l√≠mites
limites = [(-10, 10), (-10, 10)]

# Crea y ejecuta el optimizador
de = EvolucionDiferencial(
    funcion_objetivo=mi_funcion,
    limites=limites,
    tama√±o_poblacion=50,
    F=0.8,
    CR=0.7,
    max_generaciones=100
)

mejor_sol, mejor_fit = de.optimizar()
print(f"Soluci√≥n √≥ptima: {mejor_sol}")
de.graficar_convergencia()
```

### Ejemplo 2: Salida del programa

```
============================================================
ALGORITMO DE EVOLUCI√ìN DIFERENCIAL
============================================================
Dimensiones: 2
Tama√±o de poblaci√≥n: 50
Factor de mutaci√≥n (F): 0.8
Probabilidad de cruce (CR): 0.7
============================================================

Generaci√≥n   0 | Mejor fitness: 4.532100e+01
Generaci√≥n  10 | Mejor fitness: 1.234567e+00
Generaci√≥n  20 | Mejor fitness: 5.678901e-02
Generaci√≥n  50 | Mejor fitness: 1.234567e-05

============================================================
OPTIMIZACI√ìN COMPLETADA
============================================================
Mejor soluci√≥n encontrada: [0.001234, -0.002345]
Valor de fitness: 1.234567e-05
============================================================
```

## üßÆ Teor√≠a

### ¬øC√≥mo funciona el algoritmo?

El algoritmo tiene **4 pasos principales** que se repiten:

#### 1Ô∏è‚É£ Inicializaci√≥n
Crea una poblaci√≥n de N soluciones aleatorias.

#### 2Ô∏è‚É£ Mutaci√≥n Diferencial
Para cada soluci√≥n, crea un "mutante" combinando 3 soluciones aleatorias:
```
v = x_r1 + F * (x_r2 - x_r3)
```
Esta **diferencia** (x_r2 - x_r3) gu√≠a la b√∫squeda.

#### 3Ô∏è‚É£ Cruce (Crossover)
Mezcla el mutante con la soluci√≥n actual con probabilidad CR.

#### 4Ô∏è‚É£ Selecci√≥n
Solo guarda la nueva soluci√≥n si es mejor que la anterior.

### Par√°metros

| Par√°metro | S√≠mbolo | Rango | Descripci√≥n |
|-----------|---------|-------|-------------|
| Poblaci√≥n | NP | 10D-100D | N√∫mero de individuos |
| Factor de mutaci√≥n | F | 0.4-1.0 | Tama√±o de los cambios |
| Prob. de cruce | CR | 0.5-0.9 | Frecuencia de cambios |

**Configuraci√≥n recomendada:** NP=50, F=0.8, CR=0.7

### Ventajas

‚úÖ Simple de implementar  
‚úÖ Pocos par√°metros  
‚úÖ No requiere derivadas  
‚úÖ Robusto y vers√°til  
‚úÖ Funciona en funciones multimodales  

### Desventajas

‚ùå No garantiza √≥ptimo global  
‚ùå Requiere muchas evaluaciones  
‚ùå Sensible a par√°metros  

## üéì Para Estudiantes

Este proyecto fue dise√±ado espec√≠ficamente para fines educativos:

- ‚úÖ C√≥digo ampliamente comentado
- ‚úÖ M√∫ltiples niveles de complejidad
- ‚úÖ Ejemplos visuales paso a paso
- ‚úÖ Documentaci√≥n en espa√±ol
- ‚úÖ Referencias acad√©micas incluidas

### Perfecto para:
- Proyectos universitarios
- Presentaciones en clase
- Aprender algoritmos evolutivos
- Optimizaci√≥n de problemas reales

## üìö Referencias

1. **Storn, R., & Price, K. (1997)**. "Differential evolution‚Äìa simple and efficient heuristic for global optimization over continuous spaces". *Journal of global optimization*, 11(4), 341-359.

2. **Price, K., Storn, R. M., & Lampinen, J. A. (2006)**. "Differential evolution: a practical approach to global optimization". Springer Science & Business Media.

3. **Das, S., & Suganthan, P. N. (2011)**. "Differential evolution: a survey of the state-of-the-art". *IEEE transactions on evolutionary computation*, 15(1), 4-31.

## ü§ù Contribuir

Las contribuciones son bienvenidas. Si deseas mejorar este proyecto:

1. Haz un Fork del proyecto
2. Crea una rama para tu caracter√≠stica (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## üìù Licencia

Este proyecto est√° bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para m√°s detalles.

## üë®‚Äçüíª Autor

Proyecto creado con fines educativos para la universidad.

## üåü Agradecimientos

- Rainer Storn y Kenneth Price por crear el algoritmo
- La comunidad acad√©mica por las implementaciones de referencia
- Todos los que contribuyan a mejorar este proyecto

---

<p align="center">
  <b>‚≠ê Si este proyecto te fue √∫til, no olvides darle una estrella ‚≠ê</b>
</p>

<p align="center">
  Hecho con ‚ù§Ô∏è para estudiantes de algoritmos evolutivos
</p>

